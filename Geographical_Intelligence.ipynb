{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOTAQrAORrtlr0Nd5ANQnaR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamlidberg/Cultural-remains/blob/main/Geographical_Intelligence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and implementing a machine learning model on geospatial data"
      ],
      "metadata": {
        "id": "ZuZl2YQI5a8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start by doing the iitial setub. Clone the github repository which contains both geospatial data and field data."
      ],
      "metadata": {
        "id": "rwvABqe8olhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "!git clone https://github.com/williamlidberg/Geographical-Intelligence.git"
      ],
      "metadata": {
        "id": "Dp_TRFLkotOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The repository include a multiband raster with topographical data and field data collected by Johannes Larsson. Lets start by having a look at the field data"
      ],
      "metadata": {
        "id": "CPEB7u3UCDnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Field data"
      ],
      "metadata": {
        "id": "YYrozTaXL_sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "soildata = pd.read_csv('/content/Geographical-Intelligence/data/Krycklan_Soilsurvey_data.csv', sep=';')\n",
        "soildata"
      ],
      "metadata": {
        "id": "XWt6FjloC4nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo we will use the soil moisture class from the soildata (SMC). Soil moisture was classified into five classes in the field. We will start by inspecting the data."
      ],
      "metadata": {
        "id": "2WVNwVpYD9c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "z0e9_39tKxJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,20)\n",
        "\n",
        "gdf = gpd.GeoDataFrame(soildata, geometry=gpd.points_from_xy(soildata.East, soildata.North), crs=3006) # The coordinates are in SWEREFF 99 TM = 3006\n",
        "gdf.plot(column='SMC', cmap='viridis_r', legend=True)"
      ],
      "metadata": {
        "id": "W4hKT9WOEEIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A geodataframe can be saved as a shapefile which can be handy for later use."
      ],
      "metadata": {
        "id": "Brh8awDR8Vj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.to_file('/content/Geographical-Intelligence/data/soildata.shp')  "
      ],
      "metadata": {
        "id": "yQjByhK7O7Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Investiagte the distribution of our soil moisture classes in Krycklan"
      ],
      "metadata": {
        "id": "HViirI7ONhrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot baxplot of SMC"
      ],
      "metadata": {
        "id": "OFO_fPDKNloA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rasterdata\n",
        "\n",
        "In order to train a machine learning model you need some geospatial data.\n",
        "The following raster layers can be found under '/content/Geographical-Intelligence/data/rasters'\n",
        "\n",
        "1.   DownslopeIndex_2m\n",
        "2.   DownslopeIndex_4m\n",
        "3.   DepthToWater_1ha\n",
        "4.   DepthToWater_2ha\n",
        "5.   DepthToWater_4ha\n",
        "6.   DepthToWater_8ha\n",
        "7.   DepthToWater_16ha\n",
        "8.   DepthToWater_32ha\n",
        "9.   ElevationAboveStream_1ha\n",
        "10.  ElevationAboveStream_2ha\n",
        "11.  ElevationAboveStream_4ha\n",
        "12.  ElevationAboveStream_8ha\n",
        "13.  ElevationAboveStream_16ha\n",
        "14.  ElevationAboveStream_32ha\n",
        "15.  PennocLandformClassification\n",
        "16.  PlanCurvature\n",
        "17.  RelativeTopographicPosition\n",
        "18.  TopographicWetnessIndex\n",
        "19.  WILT\n",
        "20.  DEM\n",
        "21.  Slope\n",
        "22.  DInfFlowaccumulation\n",
        "\n",
        "You need to extract the pixel values to the field plots. This can be done using a combination of [rasterio](https://rasterio.readthedocs.io/en/latest/) and [geopandas](https://geopandas.org/en/stable/)."
      ],
      "metadata": {
        "id": "2ZeymC1oL8AQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract values to field plots"
      ],
      "metadata": {
        "id": "fMvc1EcJxrp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "8KH6qXYiTdSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import geopandas as gpd\n",
        "\n",
        "# Read points from shapefile\n",
        "soilplots = gpd.read_file('/content/Geographical-Intelligence/data/soildata.shp') # you can use the geodataframe from before but this is to demonstrate how to do it from a shapefile\n",
        "soilplots.index = range(len(soilplots))\n",
        "coords = [(x,y) for x, y in zip(soilplots.geometry.x, soilplots.geometry.y)]\n",
        "\n",
        "# Open the raster using rasterio and extract the pixel values to the geodataframe\n",
        "# dem\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/dem/16m.tif')\n",
        "soilplots['dem'] = [x[0] for x in src.sample(coords)] # Naming is important to keep things in order\n",
        "# Slope\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/Slope/16m.tif')\n",
        "soilplots['Slope'] = [x[0] for x in src.sample(coords)] \n",
        "# PlanCurvature\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/PlanCurvature/16m.tif')\n",
        "soilplots['PlanCurvature'] = [x[0] for x in src.sample(coords)] \n",
        "# RelativeTopographicPosition\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/RelativeTopographicPosition/16m.tif')\n",
        "soilplots['RelativeTopographicPosition'] = [x[0] for x in src.sample(coords)] \n",
        "# PennockLandFormClass\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/PennockLandFormClass/16m.tif')\n",
        "soilplots['PennockLandFormClass'] = [x[0] for x in src.sample(coords)] \n",
        "# TopographicWetnessIndex\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/TopographicWetnessIndex/16m.tif')\n",
        "soilplots['TopographicWetnessIndex'] = [x[0] for x in src.sample(coords)] \n",
        "# WILT\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/WILT/16m.tif')\n",
        "soilplots['WILT'] = [x[0] for x in src.sample(coords)] \n",
        "# DownslopeIndex_2m\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DownslopeIndex_2m/16m.tif')\n",
        "soilplots['DownslopeIndex_2m'] = [x[0] for x in src.sample(coords)] \n",
        "# DownslopeIndex_4m\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DownslopeIndex_4m/16m.tif')\n",
        "soilplots['DownslopeIndex_4m'] = [x[0] for x in src.sample(coords)] \n",
        "# DepthToWater_1ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DepthToWater_1ha/16m.tif')\n",
        "soilplots['DepthToWater_1ha'] = [x[0] for x in src.sample(coords)] \n",
        "# DepthToWater_2ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DepthToWater_2ha/16m.tif')\n",
        "soilplots['DepthToWater_2ha'] = [x[0] for x in src.sample(coords)] \n",
        "# DepthToWater_4ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DepthToWater_4ha/16m.tif')\n",
        "soilplots['DepthToWater_4ha'] = [x[0] for x in src.sample(coords)] \n",
        "# DepthToWater_8ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DepthToWater_8ha/16m.tif')\n",
        "soilplots['DepthToWater_8ha'] = [x[0] for x in src.sample(coords)]\n",
        "# DepthToWater_16ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DepthToWater_16ha/16m.tif')\n",
        "soilplots['DepthToWater_16ha'] = [x[0] for x in src.sample(coords)] \n",
        "# DepthToWater_32ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/DepthToWater_32ha/16m.tif')\n",
        "soilplots['DepthToWater_32ha'] = [x[0] for x in src.sample(coords)]\n",
        "# ElevationAboveStream_1ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_1ha/16m.tif')\n",
        "soilplots['ElevationAboveStream_1ha'] = [x[0] for x in src.sample(coords)]\n",
        "# ElevationAboveStream_2ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_2ha/16m.tif')\n",
        "soilplots['ElevationAboveStream_2ha'] = [x[0] for x in src.sample(coords)] \n",
        "# ElevationAboveStream_4ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_4ha/16m.tif')\n",
        "soilplots['ElevationAboveStream_4ha'] = [x[0] for x in src.sample(coords)] \n",
        "# ElevationAboveStream_8ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_8ha/16m.tif')\n",
        "soilplots['ElevationAboveStream_8ha'] = [x[0] for x in src.sample(coords)] \n",
        "# ElevationAboveStream_16ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_16ha/16m.tif')\n",
        "soilplots['ElevationAboveStream_16ha'] = [x[0] for x in src.sample(coords)] \n",
        "# ElevationAboveStream_32ha\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_32ha/16m.tif')\n",
        "soilplots['ElevationAboveStream_32ha'] = [x[0] for x in src.sample(coords)] \n",
        "\n"
      ],
      "metadata": {
        "id": "XDTV-iTLS7L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a random forest model\n",
        "In this case we will use random forest since it is a robust model that preformes well on most data with minimal tuning. Since we are only interested in soil moisture now we will drop the other Y-variables. We also need to split the data into training data and testing data. The model will be trained on the training data and evaluated on the test data. "
      ],
      "metadata": {
        "id": "xm3oBJ43MVe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "soilplots_dataframe = pd.DataFrame(soilplots.drop(columns='geometry'))\n",
        "soilplots_dataframe"
      ],
      "metadata": {
        "id": "vWHtdSUixnfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "soilplots_dataframe.drop(['Humusform', 'SMC', 'HumusformC','OTh_plot','OTh_pit','SoilType','North', 'East'], axis=1, inplace=True)\n",
        "#soilplots_dataframe.drop(['Humusform', 'SMC','OTh_plot','OTh_pit','SoilType','North', 'East'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "ZMtmsK1YcEEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into training data (80%) and testing data (20%). sklearn have a handy module for this purpose."
      ],
      "metadata": {
        "id": "bByg3ssgeRcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = soilplots_dataframe.iloc[:,0] # This is soil moisture\n",
        "x = soilplots_dataframe.iloc[:,1:] # These are all the topographical variables\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0, stratify = y)"
      ],
      "metadata": {
        "id": "qc2i8f-PePP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define and train (fit) the model. Note that we can choose between a model for [classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforest#sklearn.ensemble.RandomForestClassifier) or [regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforest#sklearn.ensemble.RandomForestRegressor). \n",
        "\n",
        "Set up a basic tune grid to try a few different combinations of hyperparameters. More details on what each of the hyperparameters do can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n"
      ],
      "metadata": {
        "id": "8rHCRHeLICXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "model = RandomForestClassifier() # note that we are using classification for the soil moisture classes\n",
        "\n",
        "\n",
        "tune_grid = {'n_estimators': [50, 100, 500],\n",
        "               'max_features': ['sqrt'],\n",
        "               'max_depth': [4,5,6],\n",
        "               'min_samples_split': [2, 5, 10],\n",
        "               'min_samples_leaf': [1, 2, 4],\n",
        "               'bootstrap': [True]}\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = model, param_distributions = tune_grid, random_state=0, n_jobs = -1)\n",
        "\n",
        "# Train the model using the defined parameters\n",
        "rf_random.fit(x_train, y_train)\n",
        "print('The best combination of hyperparameters was', rf_random.best_params_)"
      ],
      "metadata": {
        "id": "BluQh3LAIF0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test data and inspect which hyperparameters were most useful. First we need to import some more usefull tools from sklearn. Remember that the soil moisture classes were\n",
        "\n",
        "\n",
        "\n",
        "*   1 = Dry\n",
        "*   2 = Mesic\n",
        "*   3 = Mesic-moist\n",
        "*   4 = Moist\n",
        "*   2 = Wet\n"
      ],
      "metadata": {
        "id": "6PghipVhCKzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred_test = rf_random.predict(x_test)\n",
        "print(classification_report(y_test, y_pred_test, zero_division=0))"
      ],
      "metadata": {
        "id": "h6ZK_1shCRz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement model on raster data\n",
        "Now we have a working model that we want to apply to the Krycklan catchment. We need to read all the rasterlayers, apply the model and then save the result as a new raster. \n",
        "\n",
        "All rasterdata will be read into numpy arrays using gdal."
      ],
      "metadata": {
        "id": "7kw-Rk1PPEH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal_array\n",
        "import numpy as np\n",
        "# Read raster data as numeric array from file\n",
        "dem = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/dem/16m.tif')\n",
        "Slope = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/Slope/16m.tif')\n",
        "PlanCurvature = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/PlanCurvature/16m.tif')\n",
        "RelativeTopographicPosition = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/RelativeTopographicPosition/16m.tif')\n",
        "PennockLandFormClass = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/PennockLandFormClass/16m.tif')\n",
        "TopographicWetnessIndex = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/TopographicWetnessIndex/16m.tif')\n",
        "WILT = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/WILT/16m.tif')\n",
        "DownslopeIndex_2m = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DownslopeIndex_2m/16m.tif')\n",
        "DownslopeIndex_4m = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DownslopeIndex_4m/16m.tif')\n",
        "DepthToWater_1ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DepthToWater_1ha/16m.tif')\n",
        "DepthToWater_2ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DepthToWater_2ha/16m.tif')\n",
        "DepthToWater_4ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DepthToWater_4ha/16m.tif')\n",
        "DepthToWater_8ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DepthToWater_8ha/16m.tif')\n",
        "DepthToWater_16ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DepthToWater_16ha/16m.tif')\n",
        "DepthToWater_32ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/DepthToWater_32ha/16m.tif')\n",
        "ElevationAboveStream_1ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_1ha/16m.tif')\n",
        "ElevationAboveStream_2ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_2ha/16m.tif')\n",
        "ElevationAboveStream_4ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_4ha/16m.tif')\n",
        "ElevationAboveStream_8ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_8ha/16m.tif')\n",
        "ElevationAboveStream_16ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_16ha/16m.tif')\n",
        "ElevationAboveStream_32ha = gdal_array.LoadFile('/content/Geographical-Intelligence/data/rasters/ElevationAboveStream_32ha/16m.tif')\n",
        "\n"
      ],
      "metadata": {
        "id": "rQ793J5nPRQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a list of all arrays you wish to include. Note that you need to add or remove the variables in both the list and the converted dataframe."
      ],
      "metadata": {
        "id": "Hz6x2p0oe8qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a list of all arrays. you can \n",
        "list_or_all_rasters = [dem, Slope, PlanCurvature, RelativeTopographicPosition, PennockLandFormClass, TopographicWetnessIndex, WILT, DownslopeIndex_2m, DownslopeIndex_4m, DepthToWater_1ha, DepthToWater_2ha, DepthToWater_4ha, DepthToWater_8ha, DepthToWater_16ha, DepthToWater_32ha, ElevationAboveStream_1ha, ElevationAboveStream_2ha, ElevationAboveStream_4ha, ElevationAboveStream_8ha, ElevationAboveStream_16ha, ElevationAboveStream_32ha]\n",
        "\n",
        "all_data = np.array(list_or_all_rasters)\n",
        "all_data=all_data.reshape(21,738*662).T # The shape is from the original DEM\n",
        "\n",
        "df_data=pd.DataFrame(all_data,columns=['dem', 'Slope', 'PlanCurvature', 'RelativeTopographicPosition', 'PennockLandFormClass', 'TopographicWetnessIndex', 'WILT', 'DownslopeIndex_2m', 'DownslopeIndex_4m', 'DepthToWater_1ha', 'DepthToWater_2ha', 'DepthToWater_4ha', 'DepthToWater_8ha', 'DepthToWater_16ha', 'DepthToWater_32ha', 'ElevationAboveStream_1ha', 'ElevationAboveStream_2ha', 'ElevationAboveStream_4ha', 'ElevationAboveStream_8ha', 'ElevationAboveStream_16ha', 'ElevationAboveStream_32ha'])\n"
      ],
      "metadata": {
        "id": "E1F_A8Iqe-KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can finally apply the prediction to the data. Once the prediction is done you can download the predicted raster and open it in your favorite GIS software such as Qgis. "
      ],
      "metadata": {
        "id": "wnoQjbAKTv6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = rf_random.predict(df_data)\n",
        "\n",
        "# Save the data as a raster file with coordinates and extent from one of the input layers\n",
        "result = result.reshape(738,662)\n",
        "extent = rasterio.open('/content/Geographical-Intelligence/data/rasters/dem/16m.tif')\n",
        "\n",
        "with rasterio.Env():\n",
        "  profile = extent.profile\n",
        "  with rasterio.open('/content/Geographical-Intelligence/data/rasters/prediction.tif', 'w', **profile) as dst:\n",
        "        dst.write(result, 1)\n"
      ],
      "metadata": {
        "id": "KFRCi0PJNIB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also plot the result for a quick inspection"
      ],
      "metadata": {
        "id": "MjUA-uX4efpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from matplotlib import pyplot\n",
        "src = rasterio.open('/content/Geographical-Intelligence/data/rasters/prediction.tif')\n",
        "pyplot.imshow(src.read(1), cmap='RdYlBu')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "DbbnQ-Hevj3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict C/N ratio based on topographical data\n",
        "---\n",
        "\n",
        "Now you will do the same as above but instead of using classified soil moisture you will try to predict the C/N ratio from a new set of field plots from Krycklan. The data can be found here: /content/Geographical-Intelligence/data/Krycklan_Chemdata.csv\n",
        "\n",
        "Remember to change from  [classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforest#sklearn.ensemble.RandomForestClassifier) to [regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforest#sklearn.ensemble.RandomForestRegressor) and drop the apropriate columns before training the model.\n",
        "\n",
        "Good luck!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SZt6GlVWczwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "chemdata = pd.read_csv('/content/Geographical-Intelligence/data/Krycklan_Chemdata.csv', sep=';')\n",
        "chemdata"
      ],
      "metadata": {
        "id": "wuvtGLa2CiSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract more variables with Whitebox Tools\n",
        "---\n",
        "[Whitebox Tools](https://www.whiteboxgeo.com/manual/wbt_book/preface.html) Is a great software topographical modeling. This section describes how to extract additional topographical features. This is an example on how to set up Whitebox Tools and extract aspect from the original DEM.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-_g2-7XX5Ym6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whitebox\n",
        "import whitebox\n",
        "wbt = whitebox.WhiteboxTools()\n",
        "\n",
        "wbt.aspect(\n",
        "    dem = '/content/Geographical-Intelligence/data/rasters/dem/16m.tif', \n",
        "    output = '/content/Geographical-Intelligence/data/rasters/aspect.tif', \n",
        "    zfactor=None\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZL_SCHvOZmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}